{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence, List, Dict, Any, Type, Union\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "def convert_to_list(x: Union[Any, Sequence[Any]]) -> List[Any]:\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return list(x)\n",
    "    else:\n",
    "        return [x]\n",
    "\n",
    "def load_json(path: Union[str, List[str]]) -> Union[dict, List[dict]]:\n",
    "    paths = convert_to_list(path)\n",
    "    \n",
    "    data = None\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            raise ValueError(f\"{path} does not exist\")\n",
    "        \n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "            if isinstance(json_data, dict):\n",
    "                if data is None:\n",
    "                    data = json_data\n",
    "                else:\n",
    "                    assert isinstance(data, dict), f\"Each previous json file contains a list of json dicts, while {path} contains only a json dict\"\n",
    "                    data.update(json_data)\n",
    "            elif isinstance(json_data, list):\n",
    "                if data is None:\n",
    "                    data = json_data\n",
    "                else:\n",
    "                    assert isinstance(data, list), f\"Each previous json file contains a json dict, while {path} contains only a list of json dicts\"\n",
    "                    data.extend(json_data)\n",
    "            else:\n",
    "                raise ValueError(f\"{path} is not a valid json file\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "def load_jsonl(path: Union[str, List[str]]) -> List[dict]:\n",
    "    paths = convert_to_list(path)\n",
    "    \n",
    "    data = []\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            raise ValueError(f\"{path} does not exist\")\n",
    "        \n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_json(data: Union[dict, List[dict]], path: str) -> None:\n",
    "    if not path.endswith(\".json\"):\n",
    "        raise ValueError(f\"{path} is not a json file\")\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "        \n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def save_jsonl(data: List[dict], path: str) -> None:\n",
    "    if not path.endswith(\".jsonl\"):\n",
    "        raise ValueError(f\"{path} is not a jsonl file\")\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "        \n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in data:\n",
    "            f.write(json.dumps(line, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./original/claude_multi_instruct_30k.json\"\n",
    "test_data_path = \"./original/claude_multi_instruct_1k.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_json(train_data_path)\n",
    "test_data = load_json(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32170,\n",
       " 1020,\n",
       " dict_keys(['instruction', 'output']),\n",
       " dict_keys(['instruction', 'output']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), test_data[0].keys(), train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Compose a comprehensive summary explaining the main principles behind gravity, how it works, and its role in shaping the known universe. Include the following:\n",
      "\n",
      "- A definition of gravity in simple terms and its relationship to mass and acceleration. \n",
      "- An overview of Isaac Newton's theory of universal gravitation and how it explains the attraction between objects with mass. Discuss both Newton's law of gravitation and universal law of gravitation.\n",
      "- Albert Einstein's theory of general relativity and how it revolutionized the understanding of gravity as the curvature of spacetime caused by massive objects. Compare and contrast it with Newton's theory.    \n",
      "- The latest scientific theories and research regarding the nature of gravity, including gravitational waves, extra dimensions, quantum gravity, and efforts to unite gravity with other fundamental forces.\n",
      "- Examples of gravity in action at different scales, from apples falling on Earth to gravitational lensing by black holes and the role of gravity in the evolution of stars, galaxies and the universe as a whole.\n",
      "\n",
      "\n",
      "Output: Gravity Summary\n",
      "\n",
      "Gravity is the force of attraction between objects with mass. According to Newton's law of gravitation, any two objects with mass exert a gravitational force of attraction on each other. The more mass the objects have, and the closer they are together, the stronger the force of gravity between them.  \n",
      "\n",
      "Isaac Newton postulated that every particle in the universe attracts every other particle with a force proportional to the product of their masses and inversely proportional to the square of the distance between them. This is known as Newton's universal law of gravitation. It explained why objects fall to the ground, and planetary motions around the Sun.\n",
      "\n",
      "However, Albert Einstein's theory of general relativity revolutionized our understanding of gravity. Einstein viewed gravity not as a force, but as a consequence of the curvature of spacetime itself caused by the presence of mass. This theory better explains phenomena like gravitational time dilation and gravitational lensing.\n",
      "\n",
      "Modern theories speculate that extra dimensions, quantum effects, or gravity behaving differently at extremely small or large scales could help to explain the mysteries of dark matter, dark energy, and reconcile gravity with the other fundamental forces.  \n",
      "\n",
      "Examples of gravity abound, from an apple falling to Earth, to the orbit of planets, to the lensing of light by galaxies, to the formation of stars and galaxies themselves which are shaped and held together by gravity. Overall, gravity shapes the structure and evolution of the entire cosmos.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Instruction: {test_data[2]['instruction']}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Output: {test_data[2]['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 ['Compose', 'a', 'comprehensive', 'summary', 'explaining', 'the', 'main', 'principles', 'behind', 'gravity,', 'how', 'it', 'works,', 'and', 'its', 'role', 'in', 'shaping', 'the', 'known', 'universe.', 'Include', 'the', 'following:', '-', 'A', 'definition', 'of', 'gravity', 'in', 'simple', 'terms', 'and', 'its', 'relationship', 'to', 'mass', 'and', 'acceleration.', '-', 'An', 'overview', 'of', 'Isaac', \"Newton's\", 'theory', 'of', 'universal', 'gravitation', 'and', 'how', 'it', 'explains', 'the', 'attraction', 'between', 'objects', 'with', 'mass.', 'Discuss', 'both', \"Newton's\", 'law', 'of', 'gravitation', 'and', 'universal', 'law', 'of', 'gravitation.', '-', 'Albert', \"Einstein's\", 'theory', 'of', 'general', 'relativity', 'and', 'how', 'it', 'revolutionized', 'the', 'understanding', 'of', 'gravity', 'as', 'the', 'curvature', 'of', 'spacetime', 'caused', 'by', 'massive', 'objects.', 'Compare', 'and', 'contrast', 'it', 'with', \"Newton's\", 'theory.', '-', 'The', 'latest', 'scientific', 'theories', 'and', 'research', 'regarding', 'the', 'nature', 'of', 'gravity,', 'including', 'gravitational', 'waves,', 'extra', 'dimensions,', 'quantum', 'gravity,', 'and', 'efforts', 'to', 'unite', 'gravity', 'with', 'other', 'fundamental', 'forces.', '-', 'Examples', 'of', 'gravity', 'in', 'action', 'at', 'different', 'scales,', 'from', 'apples', 'falling', 'on', 'Earth', 'to', 'gravitational', 'lensing', 'by', 'black', 'holes', 'and', 'the', 'role', 'of', 'gravity', 'in', 'the', 'evolution', 'of', 'stars,', 'galaxies', 'and', 'the', 'universe', 'as', 'a', 'whole.']\n"
     ]
    }
   ],
   "source": [
    "print(len(l:=test_data[2]['instruction'].split()), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_key = \"question\"\n",
    "answer_key = \"answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_ = []\n",
    "test_max_seq_len = int(500 * 0.75)\n",
    "test_max_num_samples = 300\n",
    "\n",
    "for test_sample in test_data:\n",
    "    if len(test_sample[\"instruction\"].split() + test_sample[\"output\"].split()) > test_max_seq_len:\n",
    "        continue\n",
    "    test_data_.append({\n",
    "        question_key: test_sample[\"instruction\"],\n",
    "        answer_key: test_sample[\"output\"],\n",
    "    })\n",
    "print(len(test_data_))\n",
    "\n",
    "if len(test_data_) > test_max_num_samples:\n",
    "    random.seed(42)\n",
    "    test_data_ = random.sample(test_data_, test_max_num_samples)\n",
    "\n",
    "len(test_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Compose a one-minute summary of an interesting historical trivia fact that covers the following aspects in a concise and comprehensive manner: who was involved, when and where it happened, what happened, why it is considered trivial yet fascinating, and how it shaped our modern world today. Ensure all conveyed facts are accurate and properly sourced, with no irrelevant or exaggerated details included.\n",
      "\n",
      "\n",
      "Answer: In 1718, British naval officer James Puckle invented the world's first rapid-fire machine gun, called the Puckle gun. He designed it to fire rectangular bullets at Catholic enemies and round bullets at Protestant allies. Though never widely used, the Puckle gun demonstrated that rapid-fire weapons were technologically feasible over 200 years before Gatling's popularization of the concept, showcasing Puckle's inventiveness and the bizarre mindset of tribal religious conflicts at the time. His ideas foreshadowed how rapid advances in weapon technology would characterize warfare in the centuries to come, shaping modern military strategies of firepower and attrition.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {test_data_[0][question_key]}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Answer: {test_data_[0][answer_key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_[0][question_key].split() + test_data_[0][answer_key].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9800, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_ = []\n",
    "train_max_seq_len = int(400 * 0.75)\n",
    "train_max_num_samples = 10000\n",
    "eval_ratio = 0.02\n",
    "\n",
    "\n",
    "for train_sample in train_data:\n",
    "    if len(train_sample[\"instruction\"].split() + train_sample[\"output\"].split()) > train_max_seq_len:\n",
    "        continue\n",
    "    train_data_.append({\n",
    "        question_key: train_sample[\"instruction\"],\n",
    "        answer_key: train_sample[\"output\"],\n",
    "    })\n",
    "print(len(train_data_))\n",
    "\n",
    "if len(train_data_) > train_max_num_samples:\n",
    "    random.seed(42)\n",
    "    train_data_ = random.sample(train_data_, train_max_num_samples)\n",
    "\n",
    "num_train_samples = len(train_data_)\n",
    "num_eval_samples = int(num_train_samples * eval_ratio)\n",
    "\n",
    "train_data_ = train_data_[:-num_eval_samples]\n",
    "eval_data_ = train_data_[-num_eval_samples:]\n",
    "\n",
    "len(train_data_), len(eval_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Develop an algorithm in pseudocode to perform recursive sorting  of a list containing integer values. Include comments explaining each step of the algorithm.\n",
      "\n",
      "\n",
      "Answer: recursiveSort(list)\n",
      "  // Base case - if list has one element or less, return the list \n",
      "  if length(list) <= 1:  \n",
      "    return list\n",
      "\n",
      "  // Otherwise, remove the first element to be the pivot  \n",
      "  pivot  list[0]  \n",
      "  list.remove(pivot)  \n",
      "  \n",
      "  // Initialize left and right lists   \n",
      "  left = []  \n",
      "  right = []  \n",
      " \n",
      "  // Iterate through remaining list elements  \n",
      "  for each element in list:\n",
      "  \n",
      "    // If less than pivot, add to left list \n",
      "    if element < pivot:   \n",
      "      left.append(element)\n",
      "\n",
      "    // Otherwise, add to right list\n",
      "    else:  \n",
      "      right.append(element)   \n",
      "\n",
      "  // Sort left and right recursively   \n",
      "  left = recursiveSort(left)\n",
      "  right = recursiveSort(right)\n",
      "\n",
      "  // Concatenate sorted left, pivot, and right     \n",
      "  return left + [pivot] + right\n",
      "\n",
      "In summary, this algorithm recursively calls itself to split the list into elements less than and greater than a chosen pivot point (the first element). It then sorts those left and right sublists, and finally concatenates the results with the pivot point in the middle, producing an overall sorted list. The base case handles lists of length 1 or less, simply returning the list.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {train_data_[0][question_key]}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Answer: {train_data_[0][answer_key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_[0][question_key].split() + train_data_[0][answer_key].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_save_path = \"./qa_test.jsonl\"\n",
    "train_save_path = \"./qa_train.jsonl\"\n",
    "eval_save_path = \"./qa_eval.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(test_data_, test_save_path) # 0.3k, token length < 500\n",
    "save_jsonl(train_data_, train_save_path) # 10k - 0.2k, token length < 400\n",
    "save_jsonl(eval_data_, eval_save_path) # 0.2k, token length < 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence, List, Dict, Any, Type, Union\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(x: Union[Any, Sequence[Any]]) -> List[Any]:\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return list(x)\n",
    "    else:\n",
    "        return [x]\n",
    "\n",
    "def check_valid_path(\n",
    "    path: str,\n",
    "    ext: Optional[str] = None,\n",
    "    should_exist: bool = True,\n",
    "    is_dir: bool = False,\n",
    "    create_if_not_exist: bool = False,\n",
    "    empty_if_exist: bool = False,\n",
    ") -> None:\n",
    "    if should_exist and not os.path.exists(path):\n",
    "        raise ValueError(f\"{path} does not exist\")\n",
    "        \n",
    "    if is_dir:\n",
    "        if os.path.exists(path) and not os.path.isdir(path):\n",
    "            raise ValueError(f\"{path} is not a directory\")\n",
    "        \n",
    "        if create_if_not_exist and not os.path.exists(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        if empty_if_exist and os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "    else:\n",
    "        if os.path.exists(path) and not os.path.isfile(path):\n",
    "            raise ValueError(f\"{path} is not a file\")\n",
    "        \n",
    "        if ext is not None and not path.endswith(f\".{ext}\"):\n",
    "            raise ValueError(f\"{path} is not a {ext} file\")\n",
    "        \n",
    "        if create_if_not_exist and not os.path.exists(path):\n",
    "            os.makedirs(os.path.dirname(path))\n",
    "            with open(path, \"w\") as _: pass\n",
    "        \n",
    "        if empty_if_exist and os.path.exists(path):\n",
    "            os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multithreaded(max_workers=5):\n",
    "    \"\"\"Multithread Decorator\n",
    "    \n",
    "    NOTE: this decorator assumes that: \n",
    "        1. the iterable arguments are ONLY in the *args, thus **kwargs are always the non-iterable shared ones\n",
    "        2. there's NO mutable argument that requires to be modified in-place, i.e. all of them are read-only\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            iterable_args = []\n",
    "            non_iterable_args = []\n",
    "            \n",
    "            for arg in args:\n",
    "                if isinstance(arg, (list, tuple, set)):\n",
    "                    \n",
    "                    iterable_args.append(arg)\n",
    "                else:\n",
    "                    non_iterable_args.append(arg)\n",
    "            \n",
    "            iterable_args = zip(*iterable_args)\n",
    "            \n",
    "            results = []\n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                if iterable_args:\n",
    "                    future_to_item = [\n",
    "                        executor.submit(func, *(list(items) + non_iterable_args), **kwargs)\n",
    "                        for items in iterable_args\n",
    "                    ]\n",
    "                    \n",
    "                    for i, future in enumerate(as_completed(future_to_item)):\n",
    "                        try:\n",
    "                            result = future.result()\n",
    "                        except Exception as exc:\n",
    "                            print(f'The {i}-th result generated an exception: {exc}')\n",
    "                        else:\n",
    "                            results.append(result)\n",
    "                else:\n",
    "                    results.append(func(*args, **kwargs))\n",
    "            \n",
    "            return results\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path: Union[str, List[str]]) -> List[dict]:\n",
    "    paths = convert_to_list(path)\n",
    "    \n",
    "    data = []\n",
    "    for path in paths:\n",
    "        check_valid_path(path, ext=\"jsonl\")\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            data.extend(json.loads(line) for line in lines)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_mt(\n",
    "    path: Union[str, List[str]],\n",
    "    max_workers: int = 5,\n",
    ") -> List[dict]:\n",
    "    paths = convert_to_list(path)\n",
    "    \n",
    "    @multithreaded(max_workers=max_workers)\n",
    "    def _load_line(line: str) -> Union[list, dict]:\n",
    "        return json.loads(line)\n",
    "    \n",
    "    data = []\n",
    "    for path in paths:\n",
    "        check_valid_path(path, ext=\"jsonl\")\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            # data.extend(json.loads(line) for line in lines)\n",
    "            data.extend(_load_line(lines)) # multi-thread speed-up\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "path = \"./qa_train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.053804636001586914 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "load_jsonl(path)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.32451462745666504 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "load_jsonl_mt(path)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
